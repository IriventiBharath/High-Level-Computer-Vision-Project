{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328557ec",
   "metadata": {
    "id": "328557ec"
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "id": "tD0FdYF2cPg1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tD0FdYF2cPg1",
    "outputId": "ac9ed8c9-d369-45c7-b219-239a43145694",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751445640851,
     "user_tz": -120,
     "elapsed": 12795,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "pip install langchain-groq langchain-core python-dotenv matplotlib pillow tqdm numpy pytesseract"
  },
  {
   "cell_type": "code",
   "id": "c0857e41",
   "metadata": {
    "id": "c0857e41"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES - TESSERACT OCR VERSION\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import pytesseract\n",
    "\n",
    "# LLM imports\n",
    "from langchain_groq import ChatGroq"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af38e33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af38e33a",
    "outputId": "e71b4218-2275-43d2-fdbd-c0dbed14c61a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751446244234,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "# Configuration and Setup\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nGEN_MODEL_ID = \"llama-3.1-8b-instant\"\n\n# Evaluation metrics\ndef normalize(text):\n    return text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n\ndef exact_match(pred, ground_truths):\n    pred_norm = normalize(pred)\n    return any(pred_norm == normalize(gt) for gt in ground_truths)\n\ndef f1_score(pred, ground_truths):\n    def score(pred, gt):\n        pred_tokens = normalize(pred).split()\n        gt_tokens = normalize(gt).split()\n        common = set(pred_tokens) & set(gt_tokens)\n        if not common:\n            return 0.0\n        precision = len(common) / len(pred_tokens) if pred_tokens else 0.0\n        recall = len(common) / len(gt_tokens) if gt_tokens else 0.0\n        return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n    return max(score(pred, gt) for gt in ground_truths)\n\n# Dataset loading\ndata_dir = 'docvqa_samples_300'\nimage_dir = os.path.join(data_dir, \"images\")\nmetadata_file = os.path.join(data_dir, \"metadata.json\")\noutput_csv = \"OCR_results_tesseract.csv\"\n\nwith open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n    docvqa_metadata = json.load(f)"
  },
  {
   "cell_type": "code",
   "id": "586a84c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "586a84c7",
    "outputId": "024bf0e8-254b-4270-c907-bf4c93106bb2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751445910625,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "# Tesseract OCR Setup\ndef extract_text_with_tesseract(image_path):\n    \"\"\"Extract text using Tesseract OCR\"\"\"\n    try:\n        image = Image.open(image_path)\n        text = pytesseract.image_to_string(image)\n        return text.strip()\n    except Exception as e:\n        print(f\"OCR error: {e}\")\n        return \"\"\n\nprint(\"Tesseract OCR initialized\")"
  },
  {
   "cell_type": "markdown",
   "id": "54e15084",
   "metadata": {
    "id": "54e15084"
   },
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "a032b112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a032b112",
    "outputId": "69669fdc-916a-4d36-d947-34ebeb373a29",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751448036279,
     "user_tz": -120,
     "elapsed": 521733,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "# LLM Setup and Main Processing Pipeline\nllm = ChatGroq(\n    groq_api_key=os.getenv('GROQ_API_KEY'),\n    model_name=GEN_MODEL_ID,\n    temperature=0,\n    max_tokens=512,\n    timeout=15,\n    max_retries=2,\n)\n\ndef process_document_fast(sample, image_dir, llm):\n    \"\"\"Fast processing with Tesseract OCR\"\"\"\n    try:\n        doc_id = sample['id']\n        image_filename = sample['image_filename']\n        question = sample['question']\n        ground_truth = sample['answers']\n\n        image_path = os.path.join(image_dir, image_filename)\n        \n        # Fast OCR with Tesseract\n        ocr_content = extract_text_with_tesseract(image_path)\n        if not ocr_content:\n            return None\n\n        # LLM QA\n        prompt = f\"\"\"Answer the question using only the relevant number, word, or phrase â€” no extra text.\n\n        OCR Content:\n        {ocr_content[:1500]}\n\n        Question: {question}\n        Answer:\"\"\"\n\n        try:\n            response = llm.invoke(prompt)\n            predicted_answer = str(response.content).strip()\n        except Exception:\n            predicted_answer = \"\"\n\n        # Evaluation\n        em = exact_match(predicted_answer, ground_truth)\n        f1_val = f1_score(predicted_answer, ground_truth)\n\n        return {\n            \"id\": doc_id,\n            \"image_filename\": image_filename,\n            \"question\": question,\n            \"ground_truth\": \" | \".join(ground_truth),\n            \"ocr_content\": ocr_content,\n            \"predicted_answer\": predicted_answer,\n            \"exact_match\": em,\n            \"f1_score\": round(f1_val, 2)\n        }\n    except Exception:\n        return None\n\n# Main processing pipeline\nprint(f\"Processing {len(docvqa_metadata)} documents...\")\nall_results = []\nprocessed_count = 0\n\nwith open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n    fieldnames = [\"id\", \"image_filename\", \"question\", \"ground_truth\", \"ocr_content\", \"predicted_answer\", \"exact_match\", \"f1_score\"]\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n\n    for sample in tqdm(docvqa_metadata, desc=\"Processing\"):\n        result = process_document_fast(sample, image_dir, llm)\n        if result is not None:\n            writer.writerow(result)\n            all_results.append(result)\n            processed_count += 1\n\n# Results summary\nif all_results:\n    em_scores = [r['exact_match'] for r in all_results]\n    f1_scores = [r['f1_score'] for r in all_results]\n    \n    print(f\"Processed: {processed_count}/{len(docvqa_metadata)}\")\n    print(f\"Exact Match: {np.mean(em_scores)*100:.1f}%\")\n    print(f\"F1 Score: {np.mean(f1_scores)*100:.1f}%\")\n    print(f\"Results saved to: {output_csv}\")"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}