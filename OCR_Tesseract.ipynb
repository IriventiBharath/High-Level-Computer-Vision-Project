{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328557ec",
   "metadata": {
    "id": "328557ec"
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0857e41",
   "metadata": {
    "id": "c0857e41"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES - TESSERACT OCR VERSION\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import pytesseract\n",
    "\n",
    "# LLM imports\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa34806",
   "metadata": {},
   "source": [
    "DOCVQA DATASET (RUN ONLY THE CONFIGURATION YOU WANT TO ASSESS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df987e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "data_dir = 'docvqa_samples_300'\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "metadata_file = os.path.join(data_dir, \"metadata.json\")\n",
    "output_csv = \"results/OCR_tesseract_results.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ff630",
   "metadata": {},
   "source": [
    "NEW DATASET (RUN ONLY THE CONFIGURATION YOU WANT TO ASSESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a63ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "os.environ[\"OLLAMA_NUM_GPU_LAYERS\"] = \"20\"\n",
    "data_dir = \"NewDataset\"\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "metadata_file = os.path.join(data_dir, \"metadata.json\")\n",
    "output_csv = \"results_NEWDATA/OCR_results_tesseract_NEWDATASET.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af38e33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751446244234,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "af38e33a",
    "outputId": "e71b4218-2275-43d2-fdbd-c0dbed14c61a"
   },
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "GEN_MODEL_ID = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Evaluation metrics\n",
    "def normalize(text):\n",
    "    return text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "\n",
    "def exact_match(pred, ground_truths):\n",
    "    pred_norm = normalize(pred)\n",
    "    return any(pred_norm == normalize(gt) for gt in ground_truths)\n",
    "\n",
    "def f1_score(pred, ground_truths):\n",
    "    def score(pred, gt):\n",
    "        pred_tokens = normalize(pred).split()\n",
    "        gt_tokens = normalize(gt).split()\n",
    "        common = set(pred_tokens) & set(gt_tokens)\n",
    "        if not common:\n",
    "            return 0.0\n",
    "        precision = len(common) / len(pred_tokens) if pred_tokens else 0.0\n",
    "        recall = len(common) / len(gt_tokens) if gt_tokens else 0.0\n",
    "        return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return max(score(pred, gt) for gt in ground_truths)\n",
    "\n",
    "\n",
    "with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    docvqa_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586a84c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751445910625,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "586a84c7",
    "outputId": "024bf0e8-254b-4270-c907-bf4c93106bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract OCR initialized\n"
     ]
    }
   ],
   "source": [
    "# Tesseract OCR Setup\n",
    "def extract_text_with_tesseract(image_path):\n",
    "    \"\"\"Extract text using Tesseract OCR\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"Tesseract OCR initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e15084",
   "metadata": {
    "id": "54e15084"
   },
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a032b112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521733,
     "status": "ok",
     "timestamp": 1751448036279,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "a032b112",
    "outputId": "69669fdc-916a-4d36-d947-34ebeb373a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10/10 [00:07<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 7/10\n",
      "Exact Match: 57.1%\n",
      "F1 Score: 57.1%\n",
      "Results saved to: OCR_results_tesseract_NEWDATASET.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LLM Setup and Main Processing Pipeline\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.getenv('GROQ_API_KEY'),\n",
    "    model_name=GEN_MODEL_ID,\n",
    "    temperature=0,\n",
    "    max_tokens=512,\n",
    "    timeout=15,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "def process_document_fast(sample, image_dir, llm):\n",
    "    \"\"\"Fast processing with Tesseract OCR\"\"\"\n",
    "    try:\n",
    "        doc_id = sample['id']\n",
    "        image_filename = sample['image_filename']\n",
    "        question = sample['question']\n",
    "        ground_truth = sample['answers']\n",
    "\n",
    "        image_path = os.path.join(image_dir, image_filename)\n",
    "        \n",
    "        # Fast OCR with Tesseract\n",
    "        ocr_content = extract_text_with_tesseract(image_path)\n",
    "        if not ocr_content:\n",
    "            return None\n",
    "\n",
    "        # LLM QA\n",
    "        prompt = f\"\"\"Answer the question using only the relevant number, word, or phrase — no extra text.\n",
    "\n",
    "        OCR Content:\n",
    "        {ocr_content[:1500]}\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = llm.invoke(prompt)\n",
    "            predicted_answer = str(response.content).strip()\n",
    "        except Exception:\n",
    "            predicted_answer = \"\"\n",
    "\n",
    "        # Evaluation\n",
    "        em = exact_match(predicted_answer, ground_truth)\n",
    "        f1_val = f1_score(predicted_answer, ground_truth)\n",
    "\n",
    "        return {\n",
    "            \"id\": doc_id,\n",
    "            \"image_filename\": image_filename,\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": \" | \".join(ground_truth),\n",
    "            \"ocr_content\": ocr_content,\n",
    "            \"predicted_answer\": predicted_answer,\n",
    "            \"exact_match\": em,\n",
    "            \"f1_score\": round(f1_val, 2)\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Main processing pipeline\n",
    "print(f\"Processing {len(docvqa_metadata)} documents...\")\n",
    "all_results = []\n",
    "processed_count = 0\n",
    "\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"id\", \"image_filename\", \"question\", \"ground_truth\", \"ocr_content\", \"predicted_answer\", \"exact_match\", \"f1_score\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for sample in tqdm(docvqa_metadata, desc=\"Processing\"):\n",
    "        result = process_document_fast(sample, image_dir, llm)\n",
    "        if result is not None:\n",
    "            writer.writerow(result)\n",
    "            all_results.append(result)\n",
    "            processed_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f0488",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af2f36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.571\n",
      "Average Exact Match (EM) Score: 0.571\n"
     ]
    }
   ],
   "source": [
    "# Load results from OUTPUT_CSV and compute average F1 and EM scores\n",
    "results_df = pd.read_csv(output_csv)\n",
    "avg_f1 = results_df['f1_score'].mean()\n",
    "avg_em = results_df['exact_match'].mean()\n",
    "\n",
    "print(f\"Average F1 Score: {avg_f1:.3f}\")\n",
    "print(f\"Average Exact Match (EM) Score: {avg_em:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
