{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328557ec",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e15084",
   "metadata": {},
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a9096ea",
   "metadata": {},
   "outputs": [],
   "source": "# LLaVA-Llama3 Vision Language Model Setup and Evaluation\nimport os\nimport json\nimport base64\nimport csv\nimport re\nfrom io import BytesIO\nfrom PIL import Image\nfrom langchain_ollama import OllamaLLM\nimport numpy as np\nimport string\n\n# Configuration\nos.environ[\"OLLAMA_NUM_GPU_LAYERS\"] = \"40\"\ndata_dir = \"docvqa_samples_300\"\nimage_dir = os.path.join(data_dir, \"images\")\nmetadata_file = os.path.join(data_dir, \"metadata.json\")\noutput_csv = \"vlm_results.csv\"\n\n# Load metadata\nwith open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n    metadata = json.load(f)\n\n# Evaluation functions\ndef preprocess_answer(text):\n    if not text or not isinstance(text, str):\n        return \"\"\n    text = text.lower().strip()\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = ' '.join(text.split())\n    return text\n\ndef exact_match(pred, ground_truths):\n    pred_processed = preprocess_answer(pred)\n    return any(pred_processed == preprocess_answer(gt) for gt in ground_truths)\n\ndef f1(pred, ground_truths):\n    def score(pred, gt):\n        pred_tokens = preprocess_answer(pred).split()\n        gt_tokens = preprocess_answer(gt).split()\n        common = set(pred_tokens) & set(gt_tokens)\n        if not common:\n            return 0.0\n        precision = len(common) / len(pred_tokens) if pred_tokens else 0.0\n        recall = len(common) / len(gt_tokens) if gt_tokens else 0.0\n        return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n    return max(score(pred, gt) for gt in ground_truths)\n\ndef pil_to_base64(pil_img):\n    buffered = BytesIO()\n    pil_img.save(buffered, format=\"PNG\")\n    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n\n# LLM Setup\ntry:\n    llm = OllamaLLM(model=\"llava-llama3\")\n    test_response = llm.invoke(\"Hello\")\n    print(\"✅ Ollama connection successful with llava-llama3\")\nexcept Exception as e:\n    print(f\"❌ Error connecting to Ollama: {e}\")\n\n# Main processing pipeline\nwith open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n    fieldnames = [\"id\", \"image_filename\", \"question\", \"ground_truth\", \"predicted_answer\", \"exact_match\", \"f1_score\"]\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n\n    em_scores = []\n    f1_scores = []\n\n    for i, sample in enumerate(metadata):\n        print(f\"Processing sample {i+1}/{len(metadata)}\")\n        \n        idx = sample[\"id\"]\n        img_path = os.path.join(image_dir, sample[\"image_filename\"])\n        \n        if not os.path.exists(img_path):\n            print(f\"⚠️ Image not found: {img_path}\")\n            continue\n            \n        image = Image.open(img_path)\n        question = sample[\"question\"]\n        ground_truths = sample[\"answers\"]\n\n        # Convert image to base64\n        image_b64 = pil_to_base64(image)\n\n        # Create prompt for vision model\n        prompt = f\"Question: {question}\\n\\nAnswer this question based on what you see in the image. Provide only the specific answer requested, be concise.\"\n\n        try:\n            response = llm.invoke(prompt, images=[image_b64])\n            pred_answer = str(response).strip()\n        except Exception as e:\n            pred_answer = \"\"\n            print(f\"⚠️ Error processing {sample['image_filename']}: {e}\")\n\n        em = exact_match(pred_answer, ground_truths)\n        f1_val = f1(pred_answer, ground_truths)\n\n        em_scores.append(int(em))\n        f1_scores.append(f1_val)\n\n        writer.writerow({\n            \"id\": idx,\n            \"image_filename\": sample[\"image_filename\"],\n            \"question\": question,\n            \"ground_truth\": \" | \".join(ground_truths),\n            \"predicted_answer\": pred_answer,\n            \"exact_match\": em,\n            \"f1_score\": round(f1_val, 2)\n        })\n\n# Summary\nif em_scores and f1_scores:\n    print(f\"Evaluation Summary on {len(metadata)} samples:\")\n    print(f\"Avg Exact Match: {np.mean(em_scores)*100:.2f}%\")\n    print(f\"Avg F1 Score: {np.mean(f1_scores)*100:.2f}%\")\n    print(f\"Results saved to: {output_csv}\")\nelse:\n    print(\"❌ No samples were processed successfully\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}