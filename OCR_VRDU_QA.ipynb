{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328557ec",
   "metadata": {
    "id": "328557ec"
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0857e41",
   "metadata": {
    "executionInfo": {
     "elapsed": 26041,
     "status": "ok",
     "timestamp": 1751448779536,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "c0857e41"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM imports\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Docling imports for VRDU OCR\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from langchain_docling.loader import DoclingLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ec318",
   "metadata": {},
   "source": [
    "DOC VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e64ddad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "C:\\Users\\bhara\\AppData\\Local\\Temp\\ipykernel_2460\\245134253.py:5: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  output_csv = \"results\\OCR_VRDU_results.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Dataset loading\n",
    "data_dir = \"docvqa_samples_300\"\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "metadata_file = os.path.join(data_dir, \"metadata.json\")\n",
    "output_csv = \"results\\OCR_VRDU_results.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e88d2c3",
   "metadata": {},
   "source": [
    "NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8f8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "data_dir = \"NewDataset\"\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "metadata_file = os.path.join(data_dir, \"metadata.json\")\n",
    "output_csv = \"results_NEWDATA\\OCR_VRDU_RESULTS_NEWDATASET.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af38e33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2485,
     "status": "ok",
     "timestamp": 1751448782022,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "af38e33a",
    "outputId": "0552b12a-075e-4a51-e3ab-4989f1490313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 samples from DocVQA dataset\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Dataset Setup\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Model configuration\n",
    "GEN_MODEL_ID = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Evaluation metrics functions\n",
    "def normalize(text):\n",
    "    \"\"\"Normalize text for comparison by removing punctuation and converting to lowercase.\"\"\"\n",
    "    return text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n",
    "\n",
    "def exact_match(pred, ground_truths):\n",
    "    \"\"\"Calculate exact match score between prediction and ground truths.\"\"\"\n",
    "    pred_norm = normalize(pred)\n",
    "    return any(pred_norm == normalize(gt) for gt in ground_truths)\n",
    "\n",
    "def f1_score(pred, ground_truths):\n",
    "    \"\"\"Calculate F1 score between prediction and ground truths.\"\"\"\n",
    "    def score(pred, gt):\n",
    "        pred_tokens = normalize(pred).split()\n",
    "        gt_tokens = normalize(gt).split()\n",
    "        common = set(pred_tokens) & set(gt_tokens)\n",
    "        if not common:\n",
    "            return 0.0\n",
    "        precision = len(common) / len(pred_tokens) if pred_tokens else 0.0\n",
    "        recall = len(common) / len(gt_tokens) if gt_tokens else 0.0\n",
    "        return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return max(score(pred, gt) for gt in ground_truths)\n",
    "\n",
    "\n",
    "\n",
    "# Load metadata\n",
    "with open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    docvqa_metadata = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(docvqa_metadata)} samples from DocVQA dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586a84c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751448786396,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     },
     "user_tz": -120
    },
    "id": "586a84c7",
    "outputId": "66015b2b-39f7-49b2-8b5b-ead59f91279a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRDU Document converter initialized\n"
     ]
    }
   ],
   "source": [
    "# VRDU OCR Setup\n",
    "VLM_MODEL = vlm_model_specs.SMOLDOCLING_TRANSFORMERS\n",
    "\n",
    "pipeline_options = VlmPipelineOptions(vlm_options=VLM_MODEL)\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.IMAGE: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "            pipeline_options=pipeline_options,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"VRDU Document converter initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e15084",
   "metadata": {
    "id": "54e15084"
   },
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032b112",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a032b112",
    "outputId": "0fac6c65-f69c-431c-cc31-7692c2604218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model initialized for QA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents:   0%|          | 0/10 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  10%|█         | 1/10 [03:32<31:53, 212.58s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  20%|██        | 2/10 [03:38<12:05, 90.73s/it] The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  30%|███       | 3/10 [04:27<08:21, 71.68s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  40%|████      | 4/10 [05:06<05:54, 59.09s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  50%|█████     | 5/10 [05:10<03:16, 39.26s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  60%|██████    | 6/10 [08:43<06:32, 98.21s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  70%|███████   | 7/10 [09:00<03:34, 71.49s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  80%|████████  | 8/10 [09:03<01:39, 49.98s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents:  90%|█████████ | 9/10 [09:11<00:36, 36.65s/it]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing documents: 100%|██████████| 10/10 [09:15<00:00, 55.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed: 7/10\n",
      "Average Exact Match: 28.57%\n",
      "Average F1 Score: 45.24%\n",
      "Results saved to: OCR_VRDU_RESULTS_NEWDATASET.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LLM Initialization and Main Processing Pipeline\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.getenv('GROQ_API_KEY'),  # Use environment variable\n",
    "    model_name=GEN_MODEL_ID,\n",
    "    temperature=0,\n",
    "    max_tokens=1024,\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "print(\"Language Model initialized for QA\")\n",
    "\n",
    "# Main evaluation pipeline\n",
    "processed_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"id\", \"image_filename\", \"question\", \"ground_truth\", \"ocr_content\", \"predicted_answer\", \"exact_match\", \"f1_score\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    em_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i, sample in enumerate(tqdm(docvqa_metadata, desc=\"Processing documents\")):\n",
    "        try:\n",
    "            doc_id = sample['id']\n",
    "            image_filename = sample['image_filename']\n",
    "            question = sample['question']\n",
    "            ground_truth = sample['answers']\n",
    "\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "            if not os.path.exists(image_path):\n",
    "                failed_count += 1\n",
    "                continue\n",
    "\n",
    "            # Extract OCR content using VRDU\n",
    "            loader = DoclingLoader(\n",
    "                file_path=[str(image_path)],\n",
    "                converter=doc_converter,\n",
    "                export_type=\"markdown\"\n",
    "            )\n",
    "\n",
    "            documents = loader.load()\n",
    "            if not documents or not documents[0].page_content.strip():\n",
    "                failed_count += 1\n",
    "                continue\n",
    "\n",
    "            ocr_content = documents[0].page_content.strip()\n",
    "\n",
    "            # Improved LLM QA with better VRDU utilization and one-shot example\n",
    "            prompt = f\"\"\"You are analyzing structured document content that preserves layout, tables, headers, and formatting. Use the document structure to find the precise answer.\n",
    "\n",
    "EXAMPLE:\n",
    "Document: \"## Invoice Details\\n| Item | Quantity | Price |\\n|------|----------|-------|\\n| Laptop | 2 | $1,200 |\\n| Mouse | 5 | $25 |\\n\\n**Total: $2,525**\"\n",
    "Question: What is the total amount?\n",
    "Answer: $2,525\n",
    "\n",
    "Now answer this question:\n",
    "\n",
    "DOCUMENT:\n",
    "{ocr_content}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "INSTRUCTIONS: Look at the document structure including headers, tables, lists, and formatting. Find the relevant section and extract the precise answer. Return ONLY the answer - no explanations or extra text.\n",
    "\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "            try:\n",
    "                response = llm.invoke(prompt)\n",
    "                predicted_answer = str(response.content).strip()\n",
    "            except Exception:\n",
    "                predicted_answer = \"\"\n",
    "\n",
    "            # Evaluation\n",
    "            em = exact_match(predicted_answer, ground_truth)\n",
    "            f1_val = f1_score(predicted_answer, ground_truth)\n",
    "\n",
    "            em_scores.append(int(em))\n",
    "            f1_scores.append(f1_val)\n",
    "\n",
    "            writer.writerow({\n",
    "                \"id\": doc_id,\n",
    "                \"image_filename\": image_filename,\n",
    "                \"question\": question,\n",
    "                \"ground_truth\": \" | \".join(ground_truth),\n",
    "                \"ocr_content\": ocr_content,\n",
    "                \"predicted_answer\": predicted_answer,\n",
    "                \"exact_match\": em,\n",
    "                \"f1_score\": round(f1_val, 2)\n",
    "            })\n",
    "\n",
    "            processed_count += 1\n",
    "\n",
    "        except Exception:\n",
    "            failed_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9333c80",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "709aaac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.554\n",
      "Average Exact Match (EM) Score: 0.494\n"
     ]
    }
   ],
   "source": [
    "# Load results from OUTPUT_CSV and compute average F1 and EM scores\n",
    "results_df = pd.read_csv(output_csv)\n",
    "avg_f1 = results_df['f1_score'].mean()\n",
    "avg_em = results_df['exact_match'].mean()\n",
    "\n",
    "print(f\"Average F1 Score: {avg_f1:.3f}\")\n",
    "print(f\"Average Exact Match (EM) Score: {avg_em:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
