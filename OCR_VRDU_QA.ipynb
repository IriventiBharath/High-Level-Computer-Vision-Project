{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328557ec",
   "metadata": {
    "id": "328557ec"
   },
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "id": "tD0FdYF2cPg1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tD0FdYF2cPg1",
    "outputId": "de805c44-d874-4c93-efa1-2819de5c9f9a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751448735241,
     "user_tz": -120,
     "elapsed": 103157,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "pip install langchain-groq langchain-docling langchain-core python-dotenv matplotlib pillow tqdm numpy"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0857e41",
   "metadata": {
    "id": "c0857e41",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751448779536,
     "user_tz": -120,
     "elapsed": 26041,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LLM imports\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Docling imports for VRDU OCR\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import VlmPipelineOptions\n",
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "from langchain_docling.loader import DoclingLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "af38e33a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "af38e33a",
    "outputId": "0552b12a-075e-4a51-e3ab-4989f1490313",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751448782022,
     "user_tz": -120,
     "elapsed": 2485,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "# Configuration and Dataset Setup\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\n# Model configuration\nGEN_MODEL_ID = \"llama-3.1-8b-instant\"\n\n# Evaluation metrics functions\ndef normalize(text):\n    \"\"\"Normalize text for comparison by removing punctuation and converting to lowercase.\"\"\"\n    return text.lower().translate(str.maketrans('', '', string.punctuation)).strip()\n\ndef exact_match(pred, ground_truths):\n    \"\"\"Calculate exact match score between prediction and ground truths.\"\"\"\n    pred_norm = normalize(pred)\n    return any(pred_norm == normalize(gt) for gt in ground_truths)\n\ndef f1_score(pred, ground_truths):\n    \"\"\"Calculate F1 score between prediction and ground truths.\"\"\"\n    def score(pred, gt):\n        pred_tokens = normalize(pred).split()\n        gt_tokens = normalize(gt).split()\n        common = set(pred_tokens) & set(gt_tokens)\n        if not common:\n            return 0.0\n        precision = len(common) / len(pred_tokens) if pred_tokens else 0.0\n        recall = len(common) / len(gt_tokens) if gt_tokens else 0.0\n        return 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n    return max(score(pred, gt) for gt in ground_truths)\n\n# Dataset loading\ndata_dir = \"docvqa_samples_300\"\nimage_dir = os.path.join(data_dir, \"images\")\nmetadata_file = os.path.join(data_dir, \"metadata.json\")\noutput_csv = \"OCR_VRDU_results_final.csv\"\n\n# Load metadata\nwith open(metadata_file, \"r\", encoding=\"utf-8\") as f:\n    docvqa_metadata = json.load(f)\n\nprint(f\"Loaded {len(docvqa_metadata)} samples from DocVQA dataset\")"
  },
  {
   "cell_type": "code",
   "id": "586a84c7",
   "metadata": {
    "id": "586a84c7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "66015b2b-39f7-49b2-8b5b-ead59f91279a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751448786396,
     "user_tz": -120,
     "elapsed": 4,
     "user": {
      "displayName": "Bharath Vasishta",
      "userId": "13449118837481043646"
     }
    }
   },
   "outputs": [],
   "source": "# VRDU OCR Setup\nVLM_MODEL = vlm_model_specs.SMOLDOCLING_TRANSFORMERS\n\npipeline_options = VlmPipelineOptions(vlm_options=VLM_MODEL)\n\ndoc_converter = DocumentConverter(\n    format_options={\n        InputFormat.IMAGE: PdfFormatOption(\n            pipeline_cls=VlmPipeline,\n            pipeline_options=pipeline_options,\n        ),\n    }\n)\n\nprint(\"VRDU Document converter initialized\")"
  },
  {
   "cell_type": "markdown",
   "id": "54e15084",
   "metadata": {
    "id": "54e15084"
   },
   "source": [
    "Document loading"
   ]
  },
  {
   "cell_type": "code",
   "id": "a032b112",
   "metadata": {
    "id": "a032b112",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0fac6c65-f69c-431c-cc31-7692c2604218"
   },
   "outputs": [],
   "source": "# LLM Initialization and Main Processing Pipeline\nllm = ChatGroq(\n    groq_api_key=os.getenv('GROQ_API_KEY'),  # Use environment variable\n    model_name=GEN_MODEL_ID,\n    temperature=0,\n    max_tokens=1024,\n    timeout=60\n)\n\nprint(\"Language Model initialized for QA\")\n\n# Main evaluation pipeline\nprocessed_count = 0\nfailed_count = 0\n\nwith open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n    fieldnames = [\"id\", \"image_filename\", \"question\", \"ground_truth\", \"ocr_content\", \"predicted_answer\", \"exact_match\", \"f1_score\"]\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n\n    em_scores = []\n    f1_scores = []\n\n    for i, sample in enumerate(tqdm(docvqa_metadata, desc=\"Processing documents\")):\n        try:\n            doc_id = sample['id']\n            image_filename = sample['image_filename']\n            question = sample['question']\n            ground_truth = sample['answers']\n\n            image_path = os.path.join(image_dir, image_filename)\n            if not os.path.exists(image_path):\n                failed_count += 1\n                continue\n\n            # Extract OCR content using VRDU\n            loader = DoclingLoader(\n                file_path=[str(image_path)],\n                converter=doc_converter,\n                export_type=\"markdown\"\n            )\n\n            documents = loader.load()\n            if not documents or not documents[0].page_content.strip():\n                failed_count += 1\n                continue\n\n            ocr_content = documents[0].page_content.strip()\n\n            # LLM QA\n            prompt = f\"\"\"Answer the question using only the relevant number, word, or phrase â€” no extra text.\n\nOCR Text:\n{ocr_content}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n\n            try:\n                response = llm.invoke(prompt)\n                predicted_answer = str(response.content).strip()\n            except Exception:\n                predicted_answer = \"\"\n\n            # Evaluation\n            em = exact_match(predicted_answer, ground_truth)\n            f1_val = f1_score(predicted_answer, ground_truth)\n\n            em_scores.append(int(em))\n            f1_scores.append(f1_val)\n\n            writer.writerow({\n                \"id\": doc_id,\n                \"image_filename\": image_filename,\n                \"question\": question,\n                \"ground_truth\": \" | \".join(ground_truth),\n                \"ocr_content\": ocr_content,\n                \"predicted_answer\": predicted_answer,\n                \"exact_match\": em,\n                \"f1_score\": round(f1_val, 2)\n            })\n\n            processed_count += 1\n\n        except Exception:\n            failed_count += 1\n\n# Results Summary\nprint(f\"Successfully processed: {processed_count}/{len(docvqa_metadata)}\")\nif em_scores and f1_scores:\n    print(f\"Average Exact Match: {np.mean(em_scores)*100:.2f}%\")\n    print(f\"Average F1 Score: {np.mean(f1_scores)*100:.2f}%\")\nprint(f\"Results saved to: {output_csv}\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}